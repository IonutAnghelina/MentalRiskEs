{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f89c3e-525d-43d5-b676-2192d20a0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540f93c-7cd9-403f-aa2d-1dc4031cffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e01e2-1232-412d-a2bf-9c23b64ac52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(train_scores, val_scores, y_label, figsize=(8,5)):\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    ax.plot(train_scores, label='Train')\n",
    "    ax.plot(val_scores, label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend()\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56457f-a149-4a98-8f85-5a0ce0520432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_embeddings(all_messages, model, tokenizer, device, m_length=96):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for subject_messages in tqdm(all_messages):\n",
    "            input = tokenizer(subject_messages, padding=True, truncation=True, max_length=m_length, return_tensors='pt')\n",
    "            output = model(**input.to(device))\n",
    "            embeddings.append(output.last_hidden_state[:, 0, :].cpu().numpy())\n",
    "    # embeddings = torch.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd0f65-a12a-457d-8ff1-c826f6907578",
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_emoticons_to_spanish = {\n",
    "        \":)\": \"cara sonriente\",\n",
    "        \":(\": \"cara triste\",\n",
    "        \";)\": \"guiño\",\n",
    "        \":D\": \"cara riendo con los ojos abiertos\",\n",
    "        \"XD\": \"cara riendo con los ojos cerrados\",\n",
    "        \"xD\": \"cara riendo con los ojos cerrados\",\n",
    "        \":P\": \"cara sacando la lengua\",\n",
    "        \"<3\": \"corazón\",\n",
    "        \":'(\": \"cara llorando\",\n",
    "        \":-)\": \"cara sonriente\",\n",
    "        \":-(\": \"cara triste\",\n",
    "        \";-)\": \"guiño\",\n",
    "        \":-D\": \"cara riendo con los ojos abiertos\",\n",
    "        \":-P\": \"cara sacando la lengua\",\n",
    "        \"(heart)\": \"corazón\",\n",
    "        \":o\": \"cara sorprendida\",\n",
    "        \":-o\": \"cara sorprendida\",\n",
    "        \":/\": \"cara de duda\"\n",
    "    }\n",
    "\n",
    "def preprocess(text):\n",
    "    # print(text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'(ja)+', 'jaja', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'(js)+', 'jsjs', text, flags=re.IGNORECASE)\n",
    "    text = text.replace(\" @\",\"o\")\n",
    "    for x,y in textual_emoticons_to_spanish.items():\n",
    "        text = text.replace(x,y)\n",
    "    text = emoji.demojize(text,language='es')\n",
    "    spanishVowels = 'aeiouáéíóú'\n",
    "    uppercaseVowels =spanishVowels.upper()\n",
    "    for vow in spanishVowels + uppercaseVowels:\n",
    "        pattern = re.compile(f\"{vow}{vow}{vow}+\")\n",
    "        text = pattern.sub(f'{vow}',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa783d-10ba-4f79-84a2-04b4e948f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_collate(batch):\n",
    "    labels = [x[1] for x in batch]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    " \n",
    "    data = [torch.tensor(x[0], dtype=torch.float32) for x in batch]\n",
    "    batch_data = pad_sequence(data)\n",
    "    \n",
    "    lens = torch.tensor([len(x) for x in data], dtype=torch.long).unsqueeze(0).unsqueeze(-1) # 1, N, 1\n",
    "    lens -= 1\n",
    "    return batch_data, lens, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6d7e6-c70f-4fc4-9939-052f63ab8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, h_size, output_dim, dropout=0):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h_size = h_size\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=h_size, num_layers=1, batch_first=False,\n",
    "                           dropout=dropout, bidirectional=False)\n",
    "        self.classifier = nn.Linear(h_size, output_dim)\n",
    "\n",
    "    def forward(self, seq_data, seq_lens, state=None):\n",
    "        # seq_data : (S, N, input_size)\n",
    "        # seq_lens: (N,) -> numbers between 0 and S-1 -> position of last actual sample before padding\n",
    "        if state is None:\n",
    "            state = (\n",
    "                torch.zeros(1, seq_data.shape[1], self.h_size, device=seq_data.device),\n",
    "                torch.zeros(1, seq_data.shape[1], self.h_size, device=seq_data.device)\n",
    "            )\n",
    "\n",
    "        out_states, _ = self.lstm(seq_data, state) # S, N, H\n",
    "        pred_states = torch.take_along_dim(out_states, seq_lens, dim=0).squeeze() # remove seq dimension\n",
    "        out = self.classifier(pred_states)\n",
    "        return out\n",
    "\n",
    "    def predict_all_timesteps(self, seq_data, seq_lens, state=None):\n",
    "        if state is None:\n",
    "            state = (\n",
    "                torch.zeros(1, seq_data.shape[1], self.h_size, device=seq_data.device),\n",
    "                torch.zeros(1, seq_data.shape[1], self.h_size, device=seq_data.device)\n",
    "            )\n",
    "        \n",
    "        out_states, _ = self.lstm(seq_data, state) # [S, N, H]\n",
    "        logits_all = self.classifier(out_states) # [S, N, n_classes]\n",
    "        pred_all = torch.argmax(logits_all, dim=2) # [S, N]\n",
    "        ts_predictions = []\n",
    "        for i in range(pred_all.shape[1]): # batch_dim\n",
    "            ts_predictions.append(pred_all[:seq_lens[0, i].item(), i].squeeze().cpu().numpy())\n",
    "\n",
    "        return ts_predictions\n",
    "\n",
    "    def predict_one_step(self, data, states=None):\n",
    "        # data: [N, E] -> [1,N,E] # there is only 1 item in each sequence\n",
    "        # state: None or tuple([N, H], [N, H])\n",
    "        \n",
    "        if states == None:\n",
    "            # init states with zeros\n",
    "            states = (\n",
    "                torch.zeros(1, seq_data.shape[1], self.h_size, device=data.device, dtype=data.dtype),\n",
    "                torch.zeros(1, seq_data.shape[1], self.h_size, device=data.device, dtype=data.dtype)\n",
    "            )\n",
    "        \n",
    "        _, (hn, cn) = self.lstm(data, states) # ([1, N, H], [1, N, H])\n",
    "        out = self.classifier(hn.squeeze()) # [N, C]\n",
    "        predictions = torch.argmax(out, axis=-1).cpu().numpy() # [N}]\n",
    "        \n",
    "        return predictions, (hn.permute(1,0,2), cn.permute(1,0,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f41f8f-8efa-4a34-9b07-8c357b09bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tms_rnn(subject_embs, labels, net, device):\n",
    "    predictions = []\n",
    "    positions = []\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_data, batch_lens, _ = lstm_collate([(embs, label) for embs,label in zip(subject_embs, labels)]) \n",
    "        batch_data, batch_lens = batch_data.to(device), batch_lens.to(device) \n",
    "        seq_predictions = net.predict_all_timesteps(batch_data, batch_lens)\n",
    "        for i, (seq_pred, true_label) in enumerate(zip(seq_predictions, labels)):\n",
    "            idxs = np.nonzero(seq_pred)[0]\n",
    "            if len(idxs) == 0: # every prediction is 0\n",
    "                predictions.append(0)\n",
    "                positions.append(-1)\n",
    "            else:\n",
    "                predictions.append(seq_pred[idxs[0]])\n",
    "                positions.append(idxs[0])\n",
    "\n",
    "    preds = predictions\n",
    "    report = {\n",
    "        'acc': metrics.accuracy_score(labels, preds),\n",
    "        'macro_f1': metrics.f1_score(labels, preds, average='macro', zero_division=0),\n",
    "        'macro_precision': metrics.precision_score(labels, preds, average='macro', zero_division=0),\n",
    "        'macro_recall': metrics.recall_score(labels, preds, average='macro', zero_division=0),\n",
    "        'micro_f1': metrics.f1_score(labels, preds, average='micro', zero_division=0),\n",
    "        'micro_precision': metrics.precision_score(labels, preds, average='micro', zero_division=0),\n",
    "        'micro_recall': metrics.recall_score(labels, preds, average='micro', zero_division=0),\n",
    "        'cls_report': metrics.classification_report(labels, preds, zero_division=0),\n",
    "        'cfm': metrics.confusion_matrix(labels, preds)\n",
    "    }\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df054d-13f7-4da6-94de-40b9231d8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "## soft labels\n",
    "def train_gdro_rnn_sl(net, optimizer, device, criterion, train_dl, q, soft_labels, eta=0.1):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    loss = 0\n",
    "    num_batches = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    for batch_data, batch_lens, batch_labels in train_dl:\n",
    "        labels.append(batch_labels.numpy())\n",
    "        unique_batch_labels = np.unique(batch_labels.numpy())\n",
    "        \n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "        batch_lens = batch_lens.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(batch_data, batch_lens)\n",
    "        batch_losses = F.cross_entropy(out, soft_labels[batch_labels], reduction='none')\n",
    "        \n",
    "        ## compute loss here\n",
    "        for cls in unique_batch_labels:\n",
    "            idx_cls = batch_labels == cls\n",
    "            q[cls] *= (eta * batch_losses[idx_cls].mean()).exp().item()\n",
    "\n",
    "        q /= q.sum()\n",
    "\n",
    "        loss_value = 0\n",
    "        for cls in unique_batch_labels:\n",
    "            idx_cls = batch_labels == cls\n",
    "            loss_value += q[cls] * batch_losses[idx_cls].mean()\n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += loss_value.item()\n",
    "        num_batches += 1\n",
    "        batch_predictions = torch.argmax(out, axis=-1)\n",
    "        preds.append(batch_predictions.cpu().numpy())\n",
    "\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    loss = loss / num_batches\n",
    "    report = {\n",
    "        'loss': loss,\n",
    "        'acc': metrics.accuracy_score(labels, preds),\n",
    "        'macro_f1': metrics.f1_score(labels, preds, average='macro', zero_division=0),\n",
    "        'macro_precision': metrics.precision_score(labels, preds, average='macro', zero_division=0),\n",
    "        'macro_recall': metrics.recall_score(labels, preds, average='macro', zero_division=0),\n",
    "        'micro_f1': metrics.f1_score(labels, preds, average='micro', zero_division=0),\n",
    "        'micro_precision': metrics.precision_score(labels, preds, average='micro', zero_division=0),\n",
    "        'micro_recall': metrics.recall_score(labels, preds, average='micro', zero_division=0),\n",
    "        'cls_report': metrics.classification_report(labels, preds, zero_division=0),\n",
    "        'cfm': metrics.confusion_matrix(labels, preds)\n",
    "    }\n",
    "    return report, q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95d41c-8b37-4df0-abfe-cb28076998e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_gdro_rnn_sl(net, optimizer, criterion, device, train_dl, train_embs, train_labels,\n",
    "                          val_embs, val_labels, soft_labels, output_dir, max_epochs=200, n_classes=3, eta=0.1):\n",
    "    num_epochs_ni = 0\n",
    "    best_vacc = 0\n",
    "    logs = {'train':defaultdict(list), 'val':defaultdict(list), 'train_eval': defaultdict(list), 'epoch':0}\n",
    "    q = torch.ones(n_classes, dtype=torch.float32, device=device) / n_classes\n",
    "    best_macro_f1_val=0\n",
    "    \n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        train_report, q = train_gdro_rnn_sl(net, optimizer, device, criterion, train_dl, q=q, soft_labels=soft_labels, eta=eta)\n",
    "        for k in train_report.keys():\n",
    "            logs['train'][k].append(train_report[k])\n",
    "        \n",
    "        val_report = validate_tms_rnn(val_embs, val_labels, net, device)\n",
    "        for k in val_report.keys():\n",
    "            logs['val'][k].append(val_report[k])\n",
    "        \n",
    "        if val_report['macro_f1'] >= best_macro_f1_val:\n",
    "            best_macro_f1_val = val_report['macro_f1']\n",
    "            torch.save(net.cpu().state_dict(), f'{output_dir}/net_params.pt')\n",
    "\n",
    "            logs['epoch'] = epoch\n",
    "            train_report_eval = validate_tms_rnn(train_embs, train_labels, net, device)\n",
    "            for k in train_report_eval.keys():\n",
    "                logs['train_eval'][k].append(train_report_eval[k])\n",
    "    return logs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe33b0-6dce-47da-b29d-a95ad333dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbDatasetRNNAug(Dataset):\n",
    "    '''\n",
    "    For samples in class 'none' avg embeddings from a random number of messages\n",
    "    '''\n",
    "    def __init__(self, embeddings, labels, thr_rng=0.5, n_msg=10):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.emb0 = [self.embeddings[i] for i in range(len(self.labels)) if self.labels[i] == 0]\n",
    "        self.thr_rng = thr_rng\n",
    "        self.n_msg = n_msg\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels[idx] == 0:\n",
    "            nr_msg = np.random.randint(1, len(self.embeddings[idx]+1))\n",
    "            return self.embeddings[idx][:nr_msg], self.labels[idx]\n",
    "        else:\n",
    "            rnd = np.random.uniform()\n",
    "            if rnd > self.thr_rng:\n",
    "                neutral = self.emb0[np.random.randint(0, len(self.emb0))] # subject from which to take neutral comments\n",
    "                n_extra = np.random.randint(1, min(len(neutral), self.n_msg)) # number of extra comments\n",
    "                return np.concatenate([neutral[:n_extra], self.embeddings[idx]], axis=0), self.labels[idx]\n",
    "            else:\n",
    "                return self.embeddings[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf16ff4-a4fc-4dbd-9c64-f0814ac5be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data provided by the organizers for the first two tasks\n",
    "data_dir = '/path/to/data/dir'\n",
    "\n",
    "LABEL_MAP = {'none':0, 'anxiety':1, 'depression':2}\n",
    "REVERSE_LABEL_MAP = {0:'none', 1:'anxiety', 2:'depression'}\n",
    "\n",
    "CONTEXTS = ['addiction','emergency','family','work','social','other']\n",
    "CONTEXT_MAP = {c:i for i,c in enumerate(CONTEXTS)}\n",
    "CONTEXT_MAP['none'] = len(CONTEXTS)\n",
    "REVERSE_CONTEXT_MAP = {CONTEXT_MAP[c]:c for c in CONTEXT_MAP.keys()}\n",
    "\n",
    "data = {'messages':[], 'labels1':[], 'labels2':[], 'dates':[]}\n",
    "\n",
    "for split in ['trial', 'train']:\n",
    "    df = pd.read_csv(os.path.join(data_dir, split, 'gold_task2.txt'))\n",
    "    labels1 = df['label'].map(lambda x: LABEL_MAP[x]).to_list()\n",
    "    data['labels1'] += labels1\n",
    "    \n",
    "    subjects = df['Subject'].to_list()\n",
    "    messages = []\n",
    "    dates = []\n",
    "    for subject in subjects:\n",
    "        subject_data = json.load(open(os.path.join(data_dir, split, 'subjects', f'{subject}.json') , 'r', encoding='utf-8'))\n",
    "        messages.append([x['message'] for x in subject_data])\n",
    "        dates.append([x['date'] for x in subject_data])\n",
    "    data['messages'] += messages\n",
    "    data['dates'] += dates\n",
    "    data['labels2'].append(df[CONTEXTS].to_numpy().astype(np.int32))\n",
    "\n",
    "data['labels2'] = np.concatenate(data['labels2'], axis=0).astype(np.float32)\n",
    "data['labels1'] = np.array(data['labels1'], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ee610-a243-4ac5-938d-d5b07f1704d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ed166-45de-47d7-8277-d72daef94746",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['labels1']\n",
    "name = 'pysentimiento/robertuito-sentiment-analysis'\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModel.from_pretrained(name)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "embs = get_cls_embeddings(data['messages'], model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187608a-247a-4f16-a0f0-82041733ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EmbDatasetRNNAug(embs, labels, 0.7, 10)\n",
    "train_ds, test_ds = random_split(ds, [0.8, 0.2], generator=torch.Generator().manual_seed(1007))\n",
    "\n",
    "val_embs = [embs[i] for i in test_ds.indices]\n",
    "val_labels = [labels[i] for i in test_ds.indices]\n",
    "\n",
    "train_embs = [embs[i] for i in train_ds.indices]\n",
    "train_labels = [labels[i] for i in train_ds.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb40ae-26bf-4eaa-a879-7add7f0c4e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/path/to/saved/networks'\n",
    "\n",
    "soft_labels = torch.tensor([\n",
    "    [1,  0,  0],\n",
    "    [0,0.9,0.1],\n",
    "    [0,0.1,0.9],\n",
    "], dtype=torch.float32, device=device)\n",
    "test_dl = DataLoader(test_ds, batch_size=128, shuffle=False, drop_last=False,collate_fn=lstm_collate)\n",
    "\n",
    "f1s = []\n",
    "for h_size in [64, 96, 128, 160]:\n",
    "    scores = []\n",
    "    for bs in [32, 64, 96]:\n",
    "        dir_name = 'rnn' + '_gdro' + '_eval' + '_sl_09' + '_aug_07_10' + f'_h_{h_size}_bs_{bs}'\n",
    "        output_dir = os.path.join(save_dir, dir_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        random.seed(1007)\n",
    "        np.random.seed(1007)\n",
    "        torch.manual_seed(1007)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, drop_last=False,collate_fn=lstm_collate)\n",
    "        net = LSTMClassifier(embs[0].shape[-1], h_size=h_size, output_dim=len(LABEL_MAP))\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "        loss_fn = nn.CrossEntropyLoss() # not used either way in gDRO\n",
    "        \n",
    "        logs = run_train_gdro_rnn_sl(net,optimizer,loss_fn,device, train_dl, train_embs, train_labels, val_embs, val_labels, \n",
    "                                     soft_labels=soft_labels, output_dir=output_dir, max_epochs=100)\n",
    "        \n",
    "        for k in logs['train_eval'].keys():\n",
    "            if k != 'cls_report' and k != 'cfm':\n",
    "                fig, ax = make_plot(logs['train'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}.png')\n",
    "                plt.close(fig)\n",
    "                fig, ax = make_plot(logs['train_eval'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}_eval.png')\n",
    "                plt.close(fig)\n",
    "        \n",
    "        np.save(f'{output_dir}/logs.npy', logs, allow_pickle=True)\n",
    "        \n",
    "        arg = np.argmax(logs['val']['macro_f1'])\n",
    "        print(f'h_size: {h_size}, batch_size: {bs}')\n",
    "        print(arg)\n",
    "        print(f\"Val macro_f1: {logs['val']['macro_f1'][arg]:.4f} | Train_eval macro_f1: {logs['train_eval']['macro_f1'][-1]:.4f}\")\n",
    "        print('Val', logs['val']['cfm'][arg], logs['val']['cls_report'][arg], sep='\\n')\n",
    "        # print('Train', logs['train']['cfm'][arg], logs['train']['cls_report'][arg], sep='\\n')\n",
    "        print('Train_eval', logs['train_eval']['cfm'][-1], logs['train_eval']['cls_report'][-1], sep='\\n')\n",
    "        scores.append(logs['val']['macro_f1'][arg])\n",
    "    f1s.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55047b23-372e-451f-84a9-2d58a9f0aec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339466c-8426-47a4-975f-d735fc06c1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc779d9-cf14-4fe9-87c2-5d0f4aaf6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data provided by the organizers for the first two tasks\n",
    "## applies preprocessing\n",
    "data_dir = '/path/to/data/dir'\n",
    "\n",
    "LABEL_MAP = {'none':0, 'anxiety':1, 'depression':2}\n",
    "REVERSE_LABEL_MAP = {0:'none', 1:'anxiety', 2:'depression'}\n",
    "\n",
    "CONTEXTS = ['addiction','emergency','family','work','social','other']\n",
    "CONTEXT_MAP = {c:i for i,c in enumerate(CONTEXTS)}\n",
    "CONTEXT_MAP['none'] = len(CONTEXTS)\n",
    "REVERSE_CONTEXT_MAP = {CONTEXT_MAP[c]:c for c in CONTEXT_MAP.keys()}\n",
    "\n",
    "data = {'messages':[], 'labels1':[], 'labels2':[], 'dates':[]}\n",
    "\n",
    "# read data and preprocess text messages\n",
    "for split in ['trial', 'train']:\n",
    "    df = pd.read_csv(os.path.join(data_dir, split, 'gold_task2.txt'))\n",
    "    labels1 = df['label'].map(lambda x: LABEL_MAP[x]).to_list()\n",
    "    data['labels1'] += labels1\n",
    "    \n",
    "    subjects = df['Subject'].to_list()\n",
    "    messages = []\n",
    "    dates = []\n",
    "    for subject in subjects:\n",
    "        subject_data = json.load(open(os.path.join(data_dir, split, 'subjects', f'{subject}.json') , 'r', encoding='utf-8'))\n",
    "        messages.append([preprocess(x['message']) for x in subject_data])\n",
    "        dates.append([x['date'] for x in subject_data])\n",
    "    data['messages'] += messages\n",
    "    data['dates'] += dates\n",
    "    data['labels2'].append(df[CONTEXTS].to_numpy().astype(np.int32))\n",
    "\n",
    "data['labels2'] = np.concatenate(data['labels2'], axis=0).astype(np.float32)\n",
    "data['labels1'] = np.array(data['labels1'], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37269d5a-6018-42a7-8e53-383beb21ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230c927-14f9-4534-a09b-1f9ad408aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['labels1']\n",
    "name = 'pysentimiento/robertuito-sentiment-analysis'\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModel.from_pretrained(name)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "embs = get_cls_embeddings(data['messages'], model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d0547-9229-4639-b4ba-b9e4fb48bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EmbDatasetRNNAug(embs, labels, 0.7, 10)\n",
    "train_ds, test_ds = random_split(ds, [0.8, 0.2], generator=torch.Generator().manual_seed(1007))\n",
    "\n",
    "val_embs = [embs[i] for i in test_ds.indices]\n",
    "val_labels = [labels[i] for i in test_ds.indices]\n",
    "\n",
    "train_embs = [embs[i] for i in train_ds.indices]\n",
    "train_labels = [labels[i] for i in train_ds.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92026c24-f39c-4284-ae22-87cacec65672",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/path/to/saved/networks'\n",
    "soft_labels = torch.tensor([\n",
    "    [1,  0,  0],\n",
    "    [0,0.9,0.1],\n",
    "    [0,0.1,0.9],\n",
    "], dtype=torch.float32, device=device)\n",
    "test_dl = DataLoader(test_ds, batch_size=128, shuffle=False, drop_last=False,collate_fn=lstm_collate)\n",
    "\n",
    "f1s = []\n",
    "for h_size in [64, 96, 128, 160]:\n",
    "    scores = []\n",
    "    for bs in [32, 64, 96]:\n",
    "        dir_name = 'rnn_preprocess' + '_gdro' + '_eval' + '_sl_09' + '_aug_07_10' + f'_h_{h_size}_bs_{bs}'\n",
    "        output_dir = os.path.join(save_dir, dir_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        random.seed(1007)\n",
    "        np.random.seed(1007)\n",
    "        torch.manual_seed(1007)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, drop_last=False,collate_fn=lstm_collate)\n",
    "        net = LSTMClassifier(embs[0].shape[-1], h_size=h_size, output_dim=len(LABEL_MAP))\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "        loss_fn = nn.CrossEntropyLoss() # not used either way in gDRO\n",
    "        \n",
    "        logs = run_train_gdro_rnn_sl(net,optimizer,loss_fn,device, train_dl, train_embs, train_labels, val_embs, val_labels, \n",
    "                                     soft_labels=soft_labels, output_dir=output_dir, max_epochs=100)\n",
    "        \n",
    "        for k in logs['train_eval'].keys():\n",
    "            if k != 'cls_report' and k != 'cfm':\n",
    "                fig, ax = make_plot(logs['train'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}.png')\n",
    "                plt.close(fig)\n",
    "                fig, ax = make_plot(logs['train_eval'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}_eval.png')\n",
    "                plt.close(fig)\n",
    "        \n",
    "        np.save(f'{output_dir}/logs.npy', logs, allow_pickle=True)\n",
    "        \n",
    "        arg = np.argmax(logs['val']['macro_f1'])\n",
    "        print(f'h_size: {h_size}, batch_size: {bs}')\n",
    "        print(arg)\n",
    "        print(f\"Val macro_f1: {logs['val']['macro_f1'][arg]:.4f} | Train_eval macro_f1: {logs['train_eval']['macro_f1'][-1]:.4f}\")\n",
    "        print('Val', logs['val']['cfm'][arg], logs['val']['cls_report'][arg], sep='\\n')\n",
    "        # print('Train', logs['train']['cfm'][arg], logs['train']['cls_report'][arg], sep='\\n')\n",
    "        print('Train_eval', logs['train_eval']['cfm'][-1], logs['train_eval']['cls_report'][-1], sep='\\n')\n",
    "        scores.append(logs['val']['macro_f1'][arg])\n",
    "    f1s.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b92a4-4b9e-4938-af9a-795d745438ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
